{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "2Opy8roBVcho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/MyDrive/CFL_training_data/CFL_training_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCciDjiyVceS",
        "outputId": "0d680307-f92d-428d-faaa-df31607e1b50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_images = []\n",
        "output_images = []\n",
        "for image in os.listdir(os.path.join(data_path, 'input'))[:1000]:\n",
        "  input_images.append(cv2.resize(cv2.imread(os.path.join(data_path, 'input', image)), (256,256)))\n",
        "  output_images.append(cv2.resize(cv2.imread(os.path.join(data_path, 'output_core', image), cv2.IMREAD_GRAYSCALE), (256,256))/255)\n",
        "output_images = [image[..., np.newaxis] for image in output_images]"
      ],
      "metadata": {
        "id": "HT7-v9ygVlhW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFs7gDk9Uo7-"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Concatenate, Add\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n",
        "    x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n",
        "    y = conv_block(x, filters, kernel_size, padding, strides)\n",
        "    y = conv_block(y, filters, kernel_size, padding, 1)\n",
        "    if x.shape[-1] != filters:\n",
        "        x = Conv2D(filters, (1, 1), padding='same', strides=strides)(x)\n",
        "    return Add()([x, y])\n",
        "\n",
        "def build_resunet(input_shape=(256, 256, 3), num_classes=1):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = residual_block(inputs, 64)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = residual_block(pool1, 128)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = residual_block(pool2, 256)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Center\n",
        "    conv4 = residual_block(pool3, 512)\n",
        "\n",
        "    # Decoder\n",
        "    up5 = Concatenate()([UpSampling2D(size=(2, 2))(conv4), conv3])\n",
        "    conv5 = residual_block(up5, 256)\n",
        "\n",
        "    up6 = Concatenate()([UpSampling2D(size=(2, 2))(conv5), conv2])\n",
        "    conv6 = residual_block(up6, 128)\n",
        "\n",
        "    up7 = Concatenate()([UpSampling2D(size=(2, 2))(conv6), conv1])\n",
        "    conv7 = residual_block(up7, 64)\n",
        "\n",
        "    # Output\n",
        "    output = Conv2D(num_classes, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "model = build_resunet()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Concatenate, Add\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n",
        "    x = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n",
        "    y = conv_block(x, filters, kernel_size, padding, strides)\n",
        "    y = conv_block(y, filters, kernel_size, padding, 1)\n",
        "    if x.shape[-1] != filters:\n",
        "        x = Conv2D(filters, (1, 1), padding='same', strides=strides)(x)\n",
        "    return Add()([x, y])\n",
        "\n",
        "def build_resunet(input_shape=(256, 256, 3), num_classes=1):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = residual_block(inputs, 64)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = residual_block(pool1, 128)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = residual_block(pool2, 256)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Center\n",
        "    conv4 = residual_block(pool3, 512)\n",
        "\n",
        "    # Decoder with skip connections\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    up5 = Concatenate()([up5, conv3])\n",
        "    conv5 = residual_block(up5, 256)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    up6 = Concatenate()([up6, conv2])\n",
        "    conv6 = residual_block(up6, 128)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    up7 = Concatenate()([up7, conv1])\n",
        "    conv7 = residual_block(up7, 64)\n",
        "\n",
        "    # Output\n",
        "    output = Conv2D(num_classes, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "model = build_resunet()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "t_v8ZFZUApeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba181c7-8a10-442c-c713-8fabec21db9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 64)         36928     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 256, 256, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 256, 256, 64)         256       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 256, 256, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 256, 256, 64)         0         ['conv2d_2[0][0]',            \n",
            "                                                                     'activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['add[0][0]']                 \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 128, 128, 128)        512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 128, 128, 128)        147584    ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 128, 128, 128)        512       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 128)        8320      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 128, 128, 128)        0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 128, 128, 128)        0         ['conv2d_5[0][0]',            \n",
            "                                                                     'activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['add_1[0][0]']               \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 256)          1024      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 256)          590080    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 64, 64, 256)          1024      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 256)          33024     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 64, 64, 256)          0         ['conv2d_8[0][0]',            \n",
            "                                                                     'activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['add_2[0][0]']               \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 512)          2048      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 512)          2048      ['conv2d_10[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 512)          131584    ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 32, 32, 512)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 32, 32, 512)          0         ['conv2d_11[0][0]',           \n",
            "                                                                     'activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 64, 64, 512)          0         ['add_3[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 64, 64, 768)          0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 64, 64, 256)          1769728   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 64, 64, 256)          1024      ['conv2d_12[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 64, 64, 256)          1024      ['conv2d_13[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 64, 64, 256)          196864    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 64, 64, 256)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 64, 64, 256)          0         ['conv2d_14[0][0]',           \n",
            "                                                                     'activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 128, 128, 256)        0         ['add_4[0][0]']               \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 128, 128, 384)        0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 128, 128, 128)        442496    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 128, 128, 128)        512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 128, 128, 128)        512       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 128, 128, 128)        49280     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 128, 128, 128)        0         ['conv2d_17[0][0]',           \n",
            "                                                                     'activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, 256, 256, 128)        0         ['add_5[0][0]']               \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 256, 256, 192)        0         ['up_sampling2d_2[0][0]',     \n",
            " )                                                                   'add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 256, 256, 64)         110656    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 256, 256, 64)         256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 256, 256, 64)         256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 256, 256, 64)         12352     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 256, 256, 64)         0         ['conv2d_20[0][0]',           \n",
            "                                                                     'activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 256, 256, 1)          65        ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8225857 (31.38 MB)\n",
            "Trainable params: 8220225 (31.36 MB)\n",
            "Non-trainable params: 5632 (22.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "\n",
        "def dice_p_bce(in_gt, in_pred):\n",
        "    \"\"\"combine DICE and BCE\"\"\"\n",
        "    return 0.01*tf.keras.losses.binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
        "\n",
        "def true_positive_rate(y_true, y_pred):\n",
        "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)"
      ],
      "metadata": {
        "id": "SwrdRBcmWIb9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.binary_crossentropy, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
      ],
      "metadata": {
        "id": "DSECnAhuWJ7S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = os.path.join(data_path, \"{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "fVDjGI60WOKH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=np.array(input_images),\n",
        "    y=np.array(output_images),\n",
        "    validation_split=0.2,\n",
        "    batch_size=8,\n",
        "    epochs=30,\n",
        "    callbacks=[model_checkpoint_callback],\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9qA5lV8WV3n",
        "outputId": "4de46b38-374a-436c-cc60-e07f876b70e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 92s 545ms/step - loss: 1.8110 - dice_coef: 0.7814 - binary_accuracy: 0.8939 - true_positive_rate: 0.8141 - val_loss: 0.2422 - val_dice_coef: 0.8292 - val_binary_accuracy: 0.9315 - val_true_positive_rate: 0.8332\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 56s 565ms/step - loss: 0.2029 - dice_coef: 0.8527 - binary_accuracy: 0.9327 - true_positive_rate: 0.8812 - val_loss: 0.1837 - val_dice_coef: 0.8228 - val_binary_accuracy: 0.9312 - val_true_positive_rate: 0.8238\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 56s 558ms/step - loss: 0.1640 - dice_coef: 0.8524 - binary_accuracy: 0.9345 - true_positive_rate: 0.8863 - val_loss: 0.1809 - val_dice_coef: 0.8724 - val_binary_accuracy: 0.9386 - val_true_positive_rate: 0.9588\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 0.1447 - dice_coef: 0.8661 - binary_accuracy: 0.9371 - true_positive_rate: 0.8956 - val_loss: 0.3513 - val_dice_coef: 0.7088 - val_binary_accuracy: 0.9148 - val_true_positive_rate: 0.6288\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 56s 565ms/step - loss: 1.0525 - dice_coef: 0.7955 - binary_accuracy: 0.9111 - true_positive_rate: 0.8268 - val_loss: 1.6253 - val_dice_coef: 0.2086 - val_binary_accuracy: 0.8408 - val_true_positive_rate: 0.1063\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 0.1489 - dice_coef: 0.8736 - binary_accuracy: 0.9376 - true_positive_rate: 0.9000 - val_loss: 0.1611 - val_dice_coef: 0.8159 - val_binary_accuracy: 0.9308 - val_true_positive_rate: 0.7898\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 0.1250 - dice_coef: 0.8694 - binary_accuracy: 0.9384 - true_positive_rate: 0.8990 - val_loss: 0.1137 - val_dice_coef: 0.8662 - val_binary_accuracy: 0.9424 - val_true_positive_rate: 0.8481\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 0.1022 - dice_coef: 0.8767 - binary_accuracy: 0.9408 - true_positive_rate: 0.9084 - val_loss: 0.0887 - val_dice_coef: 0.8884 - val_binary_accuracy: 0.9465 - val_true_positive_rate: 0.9161\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 57s 566ms/step - loss: 0.1023 - dice_coef: 0.8728 - binary_accuracy: 0.9404 - true_positive_rate: 0.9076 - val_loss: 0.1042 - val_dice_coef: 0.8729 - val_binary_accuracy: 0.9434 - val_true_positive_rate: 0.8651\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 57s 566ms/step - loss: 0.1004 - dice_coef: 0.8739 - binary_accuracy: 0.9406 - true_positive_rate: 0.9082 - val_loss: 0.0915 - val_dice_coef: 0.8912 - val_binary_accuracy: 0.9461 - val_true_positive_rate: 0.9309\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 0.0974 - dice_coef: 0.8747 - binary_accuracy: 0.9410 - true_positive_rate: 0.9089 - val_loss: 0.0872 - val_dice_coef: 0.8931 - val_binary_accuracy: 0.9472 - val_true_positive_rate: 0.9262\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 57s 567ms/step - loss: 0.0984 - dice_coef: 0.8744 - binary_accuracy: 0.9409 - true_positive_rate: 0.9083 - val_loss: 0.1273 - val_dice_coef: 0.8383 - val_binary_accuracy: 0.9376 - val_true_positive_rate: 0.7987\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 57s 567ms/step - loss: 0.0990 - dice_coef: 0.8760 - binary_accuracy: 0.9408 - true_positive_rate: 0.9092 - val_loss: 0.0883 - val_dice_coef: 0.8772 - val_binary_accuracy: 0.9458 - val_true_positive_rate: 0.8774\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 56s 557ms/step - loss: 0.1049 - dice_coef: 0.8763 - binary_accuracy: 0.9407 - true_positive_rate: 0.9074 - val_loss: 0.0882 - val_dice_coef: 0.8628 - val_binary_accuracy: 0.9452 - val_true_positive_rate: 0.8512\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 56s 565ms/step - loss: 0.1490 - dice_coef: 0.8626 - binary_accuracy: 0.9370 - true_positive_rate: 0.8916 - val_loss: 0.2028 - val_dice_coef: 0.7873 - val_binary_accuracy: 0.9271 - val_true_positive_rate: 0.7117\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 0.1102 - dice_coef: 0.8778 - binary_accuracy: 0.9408 - true_positive_rate: 0.9063 - val_loss: 0.0928 - val_dice_coef: 0.8822 - val_binary_accuracy: 0.9458 - val_true_positive_rate: 0.8768\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 57s 570ms/step - loss: 0.0826 - dice_coef: 0.8864 - binary_accuracy: 0.9439 - true_positive_rate: 0.9196 - val_loss: 0.0749 - val_dice_coef: 0.8983 - val_binary_accuracy: 0.9491 - val_true_positive_rate: 0.9441\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 56s 558ms/step - loss: 0.0860 - dice_coef: 0.8815 - binary_accuracy: 0.9432 - true_positive_rate: 0.9174 - val_loss: 0.0757 - val_dice_coef: 0.8834 - val_binary_accuracy: 0.9486 - val_true_positive_rate: 0.8852\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 57s 567ms/step - loss: 0.0822 - dice_coef: 0.8844 - binary_accuracy: 0.9438 - true_positive_rate: 0.9193 - val_loss: 0.0868 - val_dice_coef: 0.8649 - val_binary_accuracy: 0.9454 - val_true_positive_rate: 0.8490\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 0.0916 - dice_coef: 0.8821 - binary_accuracy: 0.9424 - true_positive_rate: 0.9153 - val_loss: 0.0864 - val_dice_coef: 0.8694 - val_binary_accuracy: 0.9463 - val_true_positive_rate: 0.8641\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 57s 566ms/step - loss: 0.0891 - dice_coef: 0.8816 - binary_accuracy: 0.9429 - true_positive_rate: 0.9160 - val_loss: 0.1352 - val_dice_coef: 0.8085 - val_binary_accuracy: 0.9343 - val_true_positive_rate: 0.7512\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 0.0840 - dice_coef: 0.8850 - binary_accuracy: 0.9439 - true_positive_rate: 0.9200 - val_loss: 0.0726 - val_dice_coef: 0.8795 - val_binary_accuracy: 0.9491 - val_true_positive_rate: 0.8871\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 0.0987 - dice_coef: 0.8772 - binary_accuracy: 0.9415 - true_positive_rate: 0.9118 - val_loss: 0.2130 - val_dice_coef: 0.7514 - val_binary_accuracy: 0.9223 - val_true_positive_rate: 0.6685\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 57s 567ms/step - loss: 0.0863 - dice_coef: 0.8848 - binary_accuracy: 0.9433 - true_positive_rate: 0.9176 - val_loss: 0.0910 - val_dice_coef: 0.8518 - val_binary_accuracy: 0.9437 - val_true_positive_rate: 0.8359\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 57s 566ms/step - loss: 0.0950 - dice_coef: 0.8782 - binary_accuracy: 0.9423 - true_positive_rate: 0.9133 - val_loss: 0.1581 - val_dice_coef: 0.7762 - val_binary_accuracy: 0.9278 - val_true_positive_rate: 0.7049\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 57s 566ms/step - loss: 0.0919 - dice_coef: 0.8817 - binary_accuracy: 0.9427 - true_positive_rate: 0.9156 - val_loss: 0.0898 - val_dice_coef: 0.8691 - val_binary_accuracy: 0.9459 - val_true_positive_rate: 0.8609\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 57s 566ms/step - loss: 0.0820 - dice_coef: 0.8821 - binary_accuracy: 0.9435 - true_positive_rate: 0.9189 - val_loss: 0.0877 - val_dice_coef: 0.8701 - val_binary_accuracy: 0.9460 - val_true_positive_rate: 0.8648\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 0.0986 - dice_coef: 0.8769 - binary_accuracy: 0.9420 - true_positive_rate: 0.9148 - val_loss: 0.1467 - val_dice_coef: 0.8329 - val_binary_accuracy: 0.9354 - val_true_positive_rate: 0.7791\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 56s 565ms/step - loss: 0.0783 - dice_coef: 0.8894 - binary_accuracy: 0.9450 - true_positive_rate: 0.9242 - val_loss: 0.0996 - val_dice_coef: 0.8182 - val_binary_accuracy: 0.9396 - val_true_positive_rate: 0.7936\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 0.0790 - dice_coef: 0.8875 - binary_accuracy: 0.9445 - true_positive_rate: 0.9241 - val_loss: 0.0932 - val_dice_coef: 0.8266 - val_binary_accuracy: 0.9418 - val_true_positive_rate: 0.8113\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7939644ad870>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bn_act(x, act=True):\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if act == True:\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = bn_act(x)\n",
        "    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv\n",
        "\n",
        "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "\n",
        "    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "\n",
        "    output = tf.keras.layers.Add()([conv, shortcut])\n",
        "    return output\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):\n",
        "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
        "\n",
        "    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "\n",
        "    output = tf.keras.layers.Add()([shortcut, res])\n",
        "    return output\n",
        "\n",
        "def upsample_concat_block(x, xskip):\n",
        "    u = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    c = tf.keras.layers.Concatenate()([u, xskip])\n",
        "    return c"
      ],
      "metadata": {
        "id": "wRaYIC5uNBEC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResUNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = tf.keras.layers.Input((256, 256, 3))\n",
        "\n",
        "    ## ENCODER\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "\n",
        "    # BRIDGE\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "\n",
        "    # DECODER\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "\n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "\n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "\n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation='sigmoid')(d4)\n",
        "    model = tf.keras.models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "PhcbLxFrNXf-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResUNet()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "d7Epfq1BNq0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(os.path.join(data_path, 'final_resunet_skip_model_30_ep.hdf5'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbgzt1MHaXOS",
        "outputId": "8f2e9e15-6522-4bfe-c8eb-e525bb9c11bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YaIw-THnNANb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(np.array(input_images[:5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBX73MYOasYd",
        "outputId": "126741cb-f92b-45c1-e6cc-d7b70099e829"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "id": "kFsN_AFF6Cg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(pred[3]>0.01)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "ynJD-SrNa3uG",
        "outputId": "d40c0b89-bd31-4bc3-efa8-5828fd090aab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}